{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import urllib.request\n",
    "import e3x\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "\n",
    "# Disable future warnings.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset.\n",
    "filename = \"md17_ethanol.npz\"\n",
    "if not os.path.exists(filename):\n",
    "  print(f\"Downloading {filename} (this may take a while)...\")\n",
    "  urllib.request.urlretrieve(f\"http://www.quantum-machine.org/gdml/data/npz/{filename}\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(key, num_train, num_valid):\n",
    "  # Load the dataset.\n",
    "  dataset = np.load(filename)\n",
    "\n",
    "  # Make sure that the dataset contains enough entries.\n",
    "  num_data = len(dataset['E'])\n",
    "  num_draw = num_train + num_valid\n",
    "  if num_draw > num_data:\n",
    "    raise RuntimeError(\n",
    "      f'datasets only contains {num_data} points, requested num_train={num_train}, num_valid={num_valid}')\n",
    "\n",
    "  # Randomly draw train and validation sets from dataset.\n",
    "  choice = np.asarray(jax.random.choice(key, num_data, shape=(num_draw,), replace=False))\n",
    "  train_choice = choice[:num_train]\n",
    "  valid_choice = choice[num_train:]\n",
    "\n",
    "  # Determine mean energy of the training set.\n",
    "  mean_energy = np.mean(dataset['E'][train_choice])  # ~ -97000\n",
    "\n",
    "  # Collect and return train and validation sets.\n",
    "  train_data = dict(\n",
    "    energy=jnp.asarray(dataset['E'][train_choice, 0] - mean_energy),\n",
    "    forces=jnp.asarray(dataset['F'][train_choice]),\n",
    "    atomic_numbers=jnp.asarray(dataset['z']),\n",
    "    positions=jnp.asarray(dataset['R'][train_choice]),\n",
    "  )\n",
    "  valid_data = dict(\n",
    "    energy=jnp.asarray(dataset['E'][valid_choice, 0] - mean_energy),\n",
    "    forces=jnp.asarray(dataset['F'][valid_choice]),\n",
    "    atomic_numbers=jnp.asarray(dataset['z']),\n",
    "    positions=jnp.asarray(dataset['R'][valid_choice]),\n",
    "  )\n",
    "  return train_data, valid_data, mean_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassingModel(nn.Module):\n",
    "  features: int = 32\n",
    "  max_degree: int = 2\n",
    "  num_iterations: int = 3\n",
    "  num_basis_functions: int = 8\n",
    "  cutoff: float = 5.0\n",
    "  max_atomic_number: int = 118  # This is overkill for most applications.\n",
    "\n",
    "\n",
    "  def energy(self, atomic_numbers, positions, dst_idx, src_idx, batch_segments, batch_size):\n",
    "    # 1. Calculate displacement vectors.\n",
    "    positions_dst = e3x.ops.gather_dst(positions, dst_idx=dst_idx)\n",
    "    positions_src = e3x.ops.gather_src(positions, src_idx=src_idx)\n",
    "    displacements = positions_src - positions_dst  # Shape (num_pairs, 3).\n",
    "\n",
    "    # 2. Expand displacement vectors in basis functions.\n",
    "    basis = e3x.nn.basis(  # Shape (num_pairs, 1, (max_degree+1)**2, num_basis_functions).\n",
    "      displacements,\n",
    "      num=self.num_basis_functions,\n",
    "      max_degree=self.max_degree,\n",
    "      radial_fn=e3x.nn.reciprocal_bernstein,\n",
    "      cutoff_fn=functools.partial(e3x.nn.smooth_cutoff, cutoff=self.cutoff)\n",
    "    )\n",
    "\n",
    "    # 3. Embed atomic numbers in feature space, x has shape (num_atoms, 1, 1, features).\n",
    "    x = e3x.nn.Embed(num_embeddings=self.max_atomic_number+1, features=self.features)(atomic_numbers)\n",
    "\n",
    "    # 4. Perform iterations (message-passing + atom-wise refinement).\n",
    "    for i in range(self.num_iterations):\n",
    "      # Message-pass.\n",
    "      if i == self.num_iterations-1:  # Final iteration.\n",
    "        # Since we will only use scalar features after the final message-pass, we do not want to produce non-scalar\n",
    "        # features for efficiency reasons.\n",
    "        y = e3x.nn.MessagePass(max_degree=0, include_pseudotensors=False)(x, basis, dst_idx=dst_idx, src_idx=src_idx)\n",
    "        # After the final message pass, we can safely throw away all non-scalar features.\n",
    "        x = e3x.nn.change_max_degree_or_type(x, max_degree=0, include_pseudotensors=False)\n",
    "      else:\n",
    "        # In intermediate iterations, the message-pass should consider all possible coupling paths.\n",
    "        y = e3x.nn.MessagePass()(x, basis, dst_idx=dst_idx, src_idx=src_idx)\n",
    "      y = e3x.nn.add(x, y)\n",
    "\n",
    "      # Atom-wise refinement MLP.\n",
    "      y = e3x.nn.Dense(self.features)(y)\n",
    "      y = e3x.nn.silu(y)\n",
    "      y = e3x.nn.Dense(self.features, kernel_init=jax.nn.initializers.zeros)(y)\n",
    "\n",
    "      # Residual connection.\n",
    "      x = e3x.nn.add(x, y)\n",
    "\n",
    "    # 5. Predict atomic energies with an ordinary dense layer.\n",
    "    element_bias = self.param('element_bias', lambda rng, shape: jnp.zeros(shape), (self.max_atomic_number+1))\n",
    "    atomic_energies = nn.Dense(1, use_bias=False, kernel_init=jax.nn.initializers.zeros)(x)  # (..., Natoms, 1, 1, 1)\n",
    "    atomic_energies = jnp.squeeze(atomic_energies, axis=(-1, -2, -3))  # Squeeze last 3 dimensions.\n",
    "    atomic_energies += element_bias[atomic_numbers]\n",
    "\n",
    "    # 6. Sum atomic energies to obtain the total energy.\n",
    "    energy = jax.ops.segment_sum(atomic_energies, segment_ids=batch_segments, num_segments=batch_size)\n",
    "\n",
    "    # To be able to efficiently compute forces, our model should return a single output (instead of one for each\n",
    "    # molecule in the batch). Fortunately, since all atomic contributions only influence the energy in their own\n",
    "    # batch segment, we can simply sum the energy of all molecules in the batch to obtain a single proxy output\n",
    "    # to differentiate.\n",
    "    return -jnp.sum(energy), energy  # Forces are the negative gradient, hence the minus sign.\n",
    "\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, atomic_numbers, positions, dst_idx, src_idx, batch_segments=None, batch_size=None):\n",
    "    if batch_segments is None:\n",
    "      batch_segments = jnp.zeros_like(atomic_numbers)\n",
    "      batch_size = 1\n",
    "\n",
    "    # Since we want to also predict forces, i.e. the gradient of the energy w.r.t. positions (argument 1), we use\n",
    "    # jax.value_and_grad to create a function for predicting both energy and forces for us.\n",
    "    energy_and_forces = jax.value_and_grad(self.energy, argnums=1, has_aux=True)\n",
    "    (_, energy), forces = energy_and_forces(atomic_numbers, positions, dst_idx, src_idx, batch_segments, batch_size)\n",
    "\n",
    "    return energy, forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batches(key, data, batch_size):\n",
    "  # Determine the number of training steps per epoch.\n",
    "  data_size = len(data['energy'])\n",
    "  steps_per_epoch = data_size//batch_size\n",
    "\n",
    "  # Draw random permutations for fetching batches from the train data.\n",
    "  perms = jax.random.permutation(key, data_size)\n",
    "  perms = perms[:steps_per_epoch * batch_size]  # Skip the last batch (if incomplete).\n",
    "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "  # Prepare entries that are identical for each batch.\n",
    "  num_atoms = len(data['atomic_numbers'])\n",
    "  batch_segments = jnp.repeat(jnp.arange(batch_size), num_atoms)\n",
    "  atomic_numbers = jnp.tile(data['atomic_numbers'], batch_size)\n",
    "  offsets = jnp.arange(batch_size) * num_atoms\n",
    "  dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(num_atoms)\n",
    "  dst_idx = (dst_idx + offsets[:, None]).reshape(-1)\n",
    "  src_idx = (src_idx + offsets[:, None]).reshape(-1)\n",
    "\n",
    "  # Assemble and return batches.\n",
    "  return [\n",
    "    dict(\n",
    "        energy=data['energy'][perm],\n",
    "        forces=data['forces'][perm].reshape(-1, 3),\n",
    "        atomic_numbers=atomic_numbers,\n",
    "        positions=data['positions'][perm].reshape(-1, 3),\n",
    "        dst_idx=dst_idx,\n",
    "        src_idx=src_idx,\n",
    "        batch_segments = batch_segments,\n",
    "    )\n",
    "    for perm in perms\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_loss(energy_prediction, energy_target, forces_prediction, forces_target, forces_weight):\n",
    "  energy_loss = jnp.mean(optax.l2_loss(energy_prediction, energy_target))\n",
    "  forces_loss = jnp.mean(optax.l2_loss(forces_prediction, forces_target))\n",
    "  return energy_loss + forces_weight * forces_loss\n",
    "\n",
    "def mean_absolute_error(prediction, target):\n",
    "  return jnp.mean(jnp.abs(prediction - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=('model_apply', 'optimizer_update', 'batch_size'))\n",
    "def train_step(model_apply, optimizer_update, batch, batch_size, forces_weight, opt_state, params):\n",
    "  def loss_fn(params):\n",
    "    energy, forces = model_apply(\n",
    "      params,\n",
    "      atomic_numbers=batch['atomic_numbers'],\n",
    "      positions=batch['positions'],\n",
    "      dst_idx=batch['dst_idx'],\n",
    "      src_idx=batch['src_idx'],\n",
    "      batch_segments=batch['batch_segments'],\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "    loss = mean_squared_loss(\n",
    "      energy_prediction=energy,\n",
    "      energy_target=batch['energy'],\n",
    "      forces_prediction=forces,\n",
    "      forces_target=batch['forces'],\n",
    "      forces_weight=forces_weight\n",
    "    )\n",
    "    return loss, (energy, forces)\n",
    "  (loss, (energy, forces)), grad = jax.value_and_grad(loss_fn, has_aux=True)(params)\n",
    "  updates, opt_state = optimizer_update(grad, opt_state, params)\n",
    "  params = optax.apply_updates(params, updates)\n",
    "  energy_mae = mean_absolute_error(energy, batch['energy'])\n",
    "  forces_mae = mean_absolute_error(forces, batch['forces'])\n",
    "  return params, opt_state, loss, energy_mae, forces_mae\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('model_apply', 'batch_size'))\n",
    "def eval_step(model_apply, batch, batch_size, forces_weight, params):\n",
    "  energy, forces = model_apply(\n",
    "    params,\n",
    "    atomic_numbers=batch['atomic_numbers'],\n",
    "    positions=batch['positions'],\n",
    "    dst_idx=batch['dst_idx'],\n",
    "    src_idx=batch['src_idx'],\n",
    "    batch_segments=batch['batch_segments'],\n",
    "    batch_size=batch_size\n",
    "  )\n",
    "  loss = mean_squared_loss(\n",
    "    energy_prediction=energy,\n",
    "    energy_target=batch['energy'],\n",
    "    forces_prediction=forces,\n",
    "    forces_target=batch['forces'],\n",
    "    forces_weight=forces_weight\n",
    "  )\n",
    "  energy_mae = mean_absolute_error(energy, batch['energy'])\n",
    "  forces_mae = mean_absolute_error(forces, batch['forces'])\n",
    "  return loss, energy_mae, forces_mae\n",
    "\n",
    "\n",
    "def train_model(key, model, train_data, valid_data, num_epochs, learning_rate, forces_weight, batch_size):\n",
    "  # Initialize model parameters and optimizer state.\n",
    "  key, init_key = jax.random.split(key)\n",
    "  optimizer = optax.adam(learning_rate)\n",
    "  dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(len(train_data['atomic_numbers']))\n",
    "  params = model.init(init_key,\n",
    "    atomic_numbers=train_data['atomic_numbers'],\n",
    "    positions=train_data['positions'][0],\n",
    "    dst_idx=dst_idx,\n",
    "    src_idx=src_idx,\n",
    "  )\n",
    "  opt_state = optimizer.init(params)\n",
    "\n",
    "  # Batches for the validation set need to be prepared only once.\n",
    "  key, shuffle_key = jax.random.split(key)\n",
    "  valid_batches = prepare_batches(shuffle_key, valid_data, batch_size)\n",
    "\n",
    "  # Train for 'num_epochs' epochs.\n",
    "  for epoch in range(1, num_epochs + 1):\n",
    "    # Prepare batches.\n",
    "    key, shuffle_key = jax.random.split(key)\n",
    "    train_batches = prepare_batches(shuffle_key, train_data, batch_size)\n",
    "\n",
    "    # Loop over train batches.\n",
    "    train_loss = 0.0\n",
    "    train_energy_mae = 0.0\n",
    "    train_forces_mae = 0.0\n",
    "    for i, batch in enumerate(train_batches):\n",
    "      params, opt_state, loss, energy_mae, forces_mae = train_step(\n",
    "        model_apply=model.apply,\n",
    "        optimizer_update=optimizer.update,\n",
    "        batch=batch,\n",
    "        batch_size=batch_size,\n",
    "        forces_weight=forces_weight,\n",
    "        opt_state=opt_state,\n",
    "        params=params\n",
    "      )\n",
    "      train_loss += (loss - train_loss)/(i+1)\n",
    "      train_energy_mae += (energy_mae - train_energy_mae)/(i+1)\n",
    "      train_forces_mae += (forces_mae - train_forces_mae)/(i+1)\n",
    "\n",
    "    # Evaluate on validation set.\n",
    "    valid_loss = 0.0\n",
    "    valid_energy_mae = 0.0\n",
    "    valid_forces_mae = 0.0\n",
    "    for i, batch in enumerate(valid_batches):\n",
    "      loss, energy_mae, forces_mae = eval_step(\n",
    "        model_apply=model.apply,\n",
    "        batch=batch,\n",
    "        batch_size=batch_size,\n",
    "        forces_weight=forces_weight,\n",
    "        params=params\n",
    "      )\n",
    "      valid_loss += (loss - valid_loss)/(i+1)\n",
    "      valid_energy_mae += (energy_mae - valid_energy_mae)/(i+1)\n",
    "      valid_forces_mae += (forces_mae - valid_forces_mae)/(i+1)\n",
    "\n",
    "    # Print progress.\n",
    "    print(f\"epoch: {epoch: 3d}                    train:   valid:\")\n",
    "    print(f\"    loss [a.u.]             {train_loss : 8.3f} {valid_loss : 8.3f}\")\n",
    "    print(f\"    energy mae [kcal/mol]   {train_energy_mae: 8.3f} {valid_energy_mae: 8.3f}\")\n",
    "    print(f\"    forces mae [kcal/mol/Å] {train_forces_mae: 8.3f} {valid_forces_mae: 8.3f}\")\n",
    "\n",
    "\n",
    "  # Return final model parameters.\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters.\n",
    "features = 32\n",
    "max_degree = 1\n",
    "num_iterations = 3\n",
    "num_basis_functions = 16\n",
    "cutoff = 5.0\n",
    "\n",
    "# Training hyperparameters.\n",
    "num_train = 900\n",
    "num_valid = 100\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "forces_weight = 1.0\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1                    train:   valid:\n",
      "    loss [a.u.]              354.858  356.773\n",
      "    energy mae [kcal/mol]      3.333    3.734\n",
      "    forces mae [kcal/mol/Å]   19.506   19.367\n",
      "epoch:   2                    train:   valid:\n",
      "    loss [a.u.]              354.940  356.538\n",
      "    energy mae [kcal/mol]      3.353    3.717\n",
      "    forces mae [kcal/mol/Å]   19.504   19.360\n",
      "epoch:   3                    train:   valid:\n",
      "    loss [a.u.]              348.279  325.633\n",
      "    energy mae [kcal/mol]      3.993    3.741\n",
      "    forces mae [kcal/mol/Å]   19.180   18.414\n",
      "epoch:   4                    train:   valid:\n",
      "    loss [a.u.]              310.219  262.668\n",
      "    energy mae [kcal/mol]      5.922    8.539\n",
      "    forces mae [kcal/mol/Å]   17.580   15.437\n",
      "epoch:   5                    train:   valid:\n",
      "    loss [a.u.]              300.597  252.366\n",
      "    energy mae [kcal/mol]      5.482    8.976\n",
      "    forces mae [kcal/mol/Å]   17.157   14.495\n",
      "epoch:   6                    train:   valid:\n",
      "    loss [a.u.]              196.014  184.792\n",
      "    energy mae [kcal/mol]      6.273    9.239\n",
      "    forces mae [kcal/mol/Å]   12.994   11.635\n",
      "epoch:   7                    train:   valid:\n",
      "    loss [a.u.]              127.992   72.928\n",
      "    energy mae [kcal/mol]      5.723    2.620\n",
      "    forces mae [kcal/mol/Å]   10.202    8.475\n",
      "epoch:   8                    train:   valid:\n",
      "    loss [a.u.]               79.361   62.432\n",
      "    energy mae [kcal/mol]      4.094    4.449\n",
      "    forces mae [kcal/mol/Å]    8.308    7.244\n",
      "epoch:   9                    train:   valid:\n",
      "    loss [a.u.]               57.468   67.691\n",
      "    energy mae [kcal/mol]      3.719    6.028\n",
      "    forces mae [kcal/mol/Å]    7.028    7.070\n",
      "epoch:  10                    train:   valid:\n",
      "    loss [a.u.]               48.545   41.996\n",
      "    energy mae [kcal/mol]      3.345    3.290\n",
      "    forces mae [kcal/mol/Å]    6.542    6.199\n",
      "epoch:  11                    train:   valid:\n",
      "    loss [a.u.]               42.138   31.800\n",
      "    energy mae [kcal/mol]      3.351    2.473\n",
      "    forces mae [kcal/mol/Å]    5.963    5.336\n",
      "epoch:  12                    train:   valid:\n",
      "    loss [a.u.]               38.394   30.728\n",
      "    energy mae [kcal/mol]      3.251    2.750\n",
      "    forces mae [kcal/mol/Å]    5.653    5.165\n",
      "epoch:  13                    train:   valid:\n",
      "    loss [a.u.]               30.313   28.468\n",
      "    energy mae [kcal/mol]      2.735    2.473\n",
      "    forces mae [kcal/mol/Å]    5.145    5.012\n",
      "epoch:  14                    train:   valid:\n",
      "    loss [a.u.]               30.782   22.505\n",
      "    energy mae [kcal/mol]      3.153    2.383\n",
      "    forces mae [kcal/mol/Å]    4.971    4.456\n",
      "epoch:  15                    train:   valid:\n",
      "    loss [a.u.]               26.135   30.956\n",
      "    energy mae [kcal/mol]      2.858    1.869\n",
      "    forces mae [kcal/mol/Å]    4.626    5.654\n",
      "epoch:  16                    train:   valid:\n",
      "    loss [a.u.]               20.513   17.644\n",
      "    energy mae [kcal/mol]      2.063    1.531\n",
      "    forces mae [kcal/mol/Å]    4.300    4.174\n",
      "epoch:  17                    train:   valid:\n",
      "    loss [a.u.]               17.823   13.575\n",
      "    energy mae [kcal/mol]      2.426    1.310\n",
      "    forces mae [kcal/mol/Å]    3.811    3.618\n",
      "epoch:  18                    train:   valid:\n",
      "    loss [a.u.]               15.390   11.441\n",
      "    energy mae [kcal/mol]      2.041    1.343\n",
      "    forces mae [kcal/mol/Å]    3.645    3.238\n",
      "epoch:  19                    train:   valid:\n",
      "    loss [a.u.]               15.426   11.845\n",
      "    energy mae [kcal/mol]      2.211    2.113\n",
      "    forces mae [kcal/mol/Å]    3.581    3.149\n",
      "epoch:  20                    train:   valid:\n",
      "    loss [a.u.]               16.742   11.815\n",
      "    energy mae [kcal/mol]      2.681    1.738\n",
      "    forces mae [kcal/mol/Å]    3.496    3.230\n",
      "epoch:  21                    train:   valid:\n",
      "    loss [a.u.]               13.516   10.461\n",
      "    energy mae [kcal/mol]      2.297    1.326\n",
      "    forces mae [kcal/mol/Å]    3.256    3.026\n",
      "epoch:  22                    train:   valid:\n",
      "    loss [a.u.]               10.464    8.770\n",
      "    energy mae [kcal/mol]      1.651    1.022\n",
      "    forces mae [kcal/mol/Å]    3.034    2.840\n",
      "epoch:  23                    train:   valid:\n",
      "    loss [a.u.]               10.815    9.367\n",
      "    energy mae [kcal/mol]      1.819    1.599\n",
      "    forces mae [kcal/mol/Å]    2.994    2.865\n",
      "epoch:  24                    train:   valid:\n",
      "    loss [a.u.]               10.432    9.552\n",
      "    energy mae [kcal/mol]      1.684    1.176\n",
      "    forces mae [kcal/mol/Å]    2.976    2.951\n",
      "epoch:  25                    train:   valid:\n",
      "    loss [a.u.]               11.428   14.214\n",
      "    energy mae [kcal/mol]      2.145    1.098\n",
      "    forces mae [kcal/mol/Å]    2.878    3.748\n",
      "epoch:  26                    train:   valid:\n",
      "    loss [a.u.]                9.520    6.846\n",
      "    energy mae [kcal/mol]      1.716    1.166\n",
      "    forces mae [kcal/mol/Å]    2.793    2.429\n",
      "epoch:  27                    train:   valid:\n",
      "    loss [a.u.]                8.157    7.056\n",
      "    energy mae [kcal/mol]      1.547    1.364\n",
      "    forces mae [kcal/mol/Å]    2.575    2.455\n",
      "epoch:  28                    train:   valid:\n",
      "    loss [a.u.]                7.248   14.605\n",
      "    energy mae [kcal/mol]      1.615    3.760\n",
      "    forces mae [kcal/mol/Å]    2.414    2.675\n",
      "epoch:  29                    train:   valid:\n",
      "    loss [a.u.]               10.166    7.600\n",
      "    energy mae [kcal/mol]      1.878    1.898\n",
      "    forces mae [kcal/mol/Å]    2.811    2.373\n",
      "epoch:  30                    train:   valid:\n",
      "    loss [a.u.]                6.528    5.956\n",
      "    energy mae [kcal/mol]      1.466    0.879\n",
      "    forces mae [kcal/mol/Å]    2.312    2.430\n",
      "epoch:  31                    train:   valid:\n",
      "    loss [a.u.]                7.730    5.598\n",
      "    energy mae [kcal/mol]      1.606    0.732\n",
      "    forces mae [kcal/mol/Å]    2.490    2.318\n",
      "epoch:  32                    train:   valid:\n",
      "    loss [a.u.]               10.645    8.929\n",
      "    energy mae [kcal/mol]      2.179    0.715\n",
      "    forces mae [kcal/mol/Å]    2.745    3.121\n",
      "epoch:  33                    train:   valid:\n",
      "    loss [a.u.]                8.572   14.127\n",
      "    energy mae [kcal/mol]      1.561    4.205\n",
      "    forces mae [kcal/mol/Å]    2.646    2.253\n",
      "epoch:  34                    train:   valid:\n",
      "    loss [a.u.]                8.062    7.156\n",
      "    energy mae [kcal/mol]      1.681    0.760\n",
      "    forces mae [kcal/mol/Å]    2.543    2.683\n",
      "epoch:  35                    train:   valid:\n",
      "    loss [a.u.]                5.292    7.356\n",
      "    energy mae [kcal/mol]      1.120    2.297\n",
      "    forces mae [kcal/mol/Å]    2.167    2.197\n",
      "epoch:  36                    train:   valid:\n",
      "    loss [a.u.]                6.157    6.800\n",
      "    energy mae [kcal/mol]      1.478    0.858\n",
      "    forces mae [kcal/mol/Å]    2.217    2.492\n",
      "epoch:  37                    train:   valid:\n",
      "    loss [a.u.]                6.273    5.113\n",
      "    energy mae [kcal/mol]      1.592    1.016\n",
      "    forces mae [kcal/mol/Å]    2.185    2.174\n",
      "epoch:  38                    train:   valid:\n",
      "    loss [a.u.]                5.469    5.154\n",
      "    energy mae [kcal/mol]      1.362    1.108\n",
      "    forces mae [kcal/mol/Å]    2.105    2.121\n",
      "epoch:  39                    train:   valid:\n",
      "    loss [a.u.]                4.700   10.554\n",
      "    energy mae [kcal/mol]      1.124    3.634\n",
      "    forces mae [kcal/mol/Å]    1.975    2.019\n",
      "epoch:  40                    train:   valid:\n",
      "    loss [a.u.]                6.525    4.802\n",
      "    energy mae [kcal/mol]      1.479    1.432\n",
      "    forces mae [kcal/mol/Å]    2.269    1.899\n",
      "epoch:  41                    train:   valid:\n",
      "    loss [a.u.]                5.771    5.442\n",
      "    energy mae [kcal/mol]      1.516    1.825\n",
      "    forces mae [kcal/mol/Å]    2.100    1.922\n",
      "epoch:  42                    train:   valid:\n",
      "    loss [a.u.]                7.777    7.375\n",
      "    energy mae [kcal/mol]      1.800    0.983\n",
      "    forces mae [kcal/mol/Å]    2.392    2.673\n",
      "epoch:  43                    train:   valid:\n",
      "    loss [a.u.]                4.584    4.359\n",
      "    energy mae [kcal/mol]      1.100    0.466\n",
      "    forces mae [kcal/mol/Å]    1.996    2.082\n",
      "epoch:  44                    train:   valid:\n",
      "    loss [a.u.]                4.842    3.369\n",
      "    energy mae [kcal/mol]      1.172    0.497\n",
      "    forces mae [kcal/mol/Å]    2.019    1.792\n",
      "epoch:  45                    train:   valid:\n",
      "    loss [a.u.]                4.118    4.585\n",
      "    energy mae [kcal/mol]      1.034    1.294\n",
      "    forces mae [kcal/mol/Å]    1.894    1.905\n",
      "epoch:  46                    train:   valid:\n",
      "    loss [a.u.]                4.127    3.540\n",
      "    energy mae [kcal/mol]      1.219    0.539\n",
      "    forces mae [kcal/mol/Å]    1.805    1.880\n",
      "epoch:  47                    train:   valid:\n",
      "    loss [a.u.]                5.698    5.405\n",
      "    energy mae [kcal/mol]      1.503    1.851\n",
      "    forces mae [kcal/mol/Å]    2.073    1.888\n",
      "epoch:  48                    train:   valid:\n",
      "    loss [a.u.]                4.034   13.325\n",
      "    energy mae [kcal/mol]      1.087    4.511\n",
      "    forces mae [kcal/mol/Å]    1.820    1.795\n",
      "epoch:  49                    train:   valid:\n",
      "    loss [a.u.]                7.733    5.561\n",
      "    energy mae [kcal/mol]      1.775    1.504\n",
      "    forces mae [kcal/mol/Å]    2.401    2.096\n",
      "epoch:  50                    train:   valid:\n",
      "    loss [a.u.]                4.354    4.691\n",
      "    energy mae [kcal/mol]      0.963    1.571\n",
      "    forces mae [kcal/mol/Å]    1.965    1.810\n",
      "epoch:  51                    train:   valid:\n",
      "    loss [a.u.]                3.818    6.612\n",
      "    energy mae [kcal/mol]      1.031    1.687\n",
      "    forces mae [kcal/mol/Å]    1.819    2.223\n",
      "epoch:  52                    train:   valid:\n",
      "    loss [a.u.]                5.487    4.893\n",
      "    energy mae [kcal/mol]      1.431    0.760\n",
      "    forces mae [kcal/mol/Å]    2.060    2.230\n",
      "epoch:  53                    train:   valid:\n",
      "    loss [a.u.]                5.560    8.836\n",
      "    energy mae [kcal/mol]      1.485    2.404\n",
      "    forces mae [kcal/mol/Å]    2.037    2.471\n",
      "epoch:  54                    train:   valid:\n",
      "    loss [a.u.]                5.472    3.097\n",
      "    energy mae [kcal/mol]      1.161    0.556\n",
      "    forces mae [kcal/mol/Å]    2.154    1.700\n",
      "epoch:  55                    train:   valid:\n",
      "    loss [a.u.]                4.346    4.043\n",
      "    energy mae [kcal/mol]      1.234    0.780\n",
      "    forces mae [kcal/mol/Å]    1.835    1.993\n",
      "epoch:  56                    train:   valid:\n",
      "    loss [a.u.]                4.342    4.404\n",
      "    energy mae [kcal/mol]      1.184    0.878\n",
      "    forces mae [kcal/mol/Å]    1.880    1.941\n",
      "epoch:  57                    train:   valid:\n",
      "    loss [a.u.]                6.092    4.903\n",
      "    energy mae [kcal/mol]      1.487    0.543\n",
      "    forces mae [kcal/mol/Å]    2.170    2.198\n",
      "epoch:  58                    train:   valid:\n",
      "    loss [a.u.]                3.917    2.689\n",
      "    energy mae [kcal/mol]      1.084    0.542\n",
      "    forces mae [kcal/mol/Å]    1.810    1.621\n",
      "epoch:  59                    train:   valid:\n",
      "    loss [a.u.]                4.218    3.534\n",
      "    energy mae [kcal/mol]      1.198    0.675\n",
      "    forces mae [kcal/mol/Å]    1.835    1.861\n",
      "epoch:  60                    train:   valid:\n",
      "    loss [a.u.]                4.434    6.708\n",
      "    energy mae [kcal/mol]      1.211    2.598\n",
      "    forces mae [kcal/mol/Å]    1.921    1.827\n",
      "epoch:  61                    train:   valid:\n",
      "    loss [a.u.]                3.999    2.951\n",
      "    energy mae [kcal/mol]      1.136    0.523\n",
      "    forces mae [kcal/mol/Å]    1.818    1.708\n",
      "epoch:  62                    train:   valid:\n",
      "    loss [a.u.]                3.971    5.945\n",
      "    energy mae [kcal/mol]      1.195    1.636\n",
      "    forces mae [kcal/mol/Å]    1.783    2.113\n",
      "epoch:  63                    train:   valid:\n",
      "    loss [a.u.]                3.456    3.058\n",
      "    energy mae [kcal/mol]      0.970    0.570\n",
      "    forces mae [kcal/mol/Å]    1.702    1.708\n",
      "epoch:  64                    train:   valid:\n",
      "    loss [a.u.]                3.945    4.700\n",
      "    energy mae [kcal/mol]      1.136    1.309\n",
      "    forces mae [kcal/mol/Å]    1.776    1.938\n",
      "epoch:  65                    train:   valid:\n",
      "    loss [a.u.]                4.666    3.915\n",
      "    energy mae [kcal/mol]      1.239    1.290\n",
      "    forces mae [kcal/mol/Å]    1.871    1.733\n",
      "epoch:  66                    train:   valid:\n",
      "    loss [a.u.]                3.771    3.857\n",
      "    energy mae [kcal/mol]      1.041    1.381\n",
      "    forces mae [kcal/mol/Å]    1.785    1.686\n",
      "epoch:  67                    train:   valid:\n",
      "    loss [a.u.]                3.946    3.221\n",
      "    energy mae [kcal/mol]      1.074    0.634\n",
      "    forces mae [kcal/mol/Å]    1.799    1.745\n",
      "epoch:  68                    train:   valid:\n",
      "    loss [a.u.]                4.279    2.602\n",
      "    energy mae [kcal/mol]      1.167    0.433\n",
      "    forces mae [kcal/mol/Å]    1.861    1.643\n",
      "epoch:  69                    train:   valid:\n",
      "    loss [a.u.]                3.132    3.025\n",
      "    energy mae [kcal/mol]      0.978    0.514\n",
      "    forces mae [kcal/mol/Å]    1.623    1.702\n",
      "epoch:  70                    train:   valid:\n",
      "    loss [a.u.]                4.762    4.792\n",
      "    energy mae [kcal/mol]      1.401    1.848\n",
      "    forces mae [kcal/mol/Å]    1.891    1.771\n",
      "epoch:  71                    train:   valid:\n",
      "    loss [a.u.]                3.822    2.763\n",
      "    energy mae [kcal/mol]      0.990    1.094\n",
      "    forces mae [kcal/mol/Å]    1.819    1.483\n",
      "epoch:  72                    train:   valid:\n",
      "    loss [a.u.]                3.695    5.420\n",
      "    energy mae [kcal/mol]      1.187    1.493\n",
      "    forces mae [kcal/mol/Å]    1.703    2.015\n",
      "epoch:  73                    train:   valid:\n",
      "    loss [a.u.]                4.770    4.068\n",
      "    energy mae [kcal/mol]      1.172    1.098\n",
      "    forces mae [kcal/mol/Å]    2.001    1.872\n",
      "epoch:  74                    train:   valid:\n",
      "    loss [a.u.]                3.088    3.017\n",
      "    energy mae [kcal/mol]      0.967    1.210\n",
      "    forces mae [kcal/mol/Å]    1.611    1.531\n",
      "epoch:  75                    train:   valid:\n",
      "    loss [a.u.]                4.398    4.394\n",
      "    energy mae [kcal/mol]      1.228    0.726\n",
      "    forces mae [kcal/mol/Å]    1.872    2.039\n",
      "epoch:  76                    train:   valid:\n",
      "    loss [a.u.]                4.491    3.716\n",
      "    energy mae [kcal/mol]      1.089    0.657\n",
      "    forces mae [kcal/mol/Å]    1.954    1.911\n",
      "epoch:  77                    train:   valid:\n",
      "    loss [a.u.]                4.772    5.243\n",
      "    energy mae [kcal/mol]      1.433    1.686\n",
      "    forces mae [kcal/mol/Å]    1.863    1.908\n",
      "epoch:  78                    train:   valid:\n",
      "    loss [a.u.]                2.880    2.225\n",
      "    energy mae [kcal/mol]      0.878    0.608\n",
      "    forces mae [kcal/mol/Å]    1.559    1.465\n",
      "epoch:  79                    train:   valid:\n",
      "    loss [a.u.]                5.262    5.999\n",
      "    energy mae [kcal/mol]      1.392    0.557\n",
      "    forces mae [kcal/mol/Å]    2.029    2.342\n",
      "epoch:  80                    train:   valid:\n",
      "    loss [a.u.]                3.608    7.581\n",
      "    energy mae [kcal/mol]      1.060    2.888\n",
      "    forces mae [kcal/mol/Å]    1.717    1.799\n",
      "epoch:  81                    train:   valid:\n",
      "    loss [a.u.]                3.486    5.843\n",
      "    energy mae [kcal/mol]      1.198    2.239\n",
      "    forces mae [kcal/mol/Å]    1.646    1.867\n",
      "epoch:  82                    train:   valid:\n",
      "    loss [a.u.]                3.325    2.244\n",
      "    energy mae [kcal/mol]      0.795    1.027\n",
      "    forces mae [kcal/mol/Å]    1.743    1.335\n",
      "epoch:  83                    train:   valid:\n",
      "    loss [a.u.]                3.771    3.130\n",
      "    energy mae [kcal/mol]      1.101    0.462\n",
      "    forces mae [kcal/mol/Å]    1.740    1.716\n",
      "epoch:  84                    train:   valid:\n",
      "    loss [a.u.]                3.363    4.489\n",
      "    energy mae [kcal/mol]      0.945    1.714\n",
      "    forces mae [kcal/mol/Å]    1.699    1.741\n",
      "epoch:  85                    train:   valid:\n",
      "    loss [a.u.]                3.902    6.715\n",
      "    energy mae [kcal/mol]      1.128    0.778\n",
      "    forces mae [kcal/mol/Å]    1.746    2.575\n",
      "epoch:  86                    train:   valid:\n",
      "    loss [a.u.]                5.995    2.894\n",
      "    energy mae [kcal/mol]      1.327    0.457\n",
      "    forces mae [kcal/mol/Å]    2.221    1.753\n",
      "epoch:  87                    train:   valid:\n",
      "    loss [a.u.]                3.047    2.918\n",
      "    energy mae [kcal/mol]      0.883    0.391\n",
      "    forces mae [kcal/mol/Å]    1.636    1.721\n",
      "epoch:  88                    train:   valid:\n",
      "    loss [a.u.]                2.702    3.224\n",
      "    energy mae [kcal/mol]      0.820    0.492\n",
      "    forces mae [kcal/mol/Å]    1.522    1.782\n",
      "epoch:  89                    train:   valid:\n",
      "    loss [a.u.]                3.918    4.193\n",
      "    energy mae [kcal/mol]      1.213    1.561\n",
      "    forces mae [kcal/mol/Å]    1.736    1.638\n",
      "epoch:  90                    train:   valid:\n",
      "    loss [a.u.]                4.289    3.718\n",
      "    energy mae [kcal/mol]      1.262    0.803\n",
      "    forces mae [kcal/mol/Å]    1.852    1.850\n",
      "epoch:  91                    train:   valid:\n",
      "    loss [a.u.]                3.716    2.451\n",
      "    energy mae [kcal/mol]      0.937    0.681\n",
      "    forces mae [kcal/mol/Å]    1.806    1.483\n",
      "epoch:  92                    train:   valid:\n",
      "    loss [a.u.]                2.807    2.920\n",
      "    energy mae [kcal/mol]      1.001    1.278\n",
      "    forces mae [kcal/mol/Å]    1.474    1.468\n",
      "epoch:  93                    train:   valid:\n",
      "    loss [a.u.]                2.832    2.497\n",
      "    energy mae [kcal/mol]      0.808    0.600\n",
      "    forces mae [kcal/mol/Å]    1.590    1.533\n",
      "epoch:  94                    train:   valid:\n",
      "    loss [a.u.]                3.266    3.618\n",
      "    energy mae [kcal/mol]      0.917    1.049\n",
      "    forces mae [kcal/mol/Å]    1.681    1.790\n",
      "epoch:  95                    train:   valid:\n",
      "    loss [a.u.]                3.221    2.407\n",
      "    energy mae [kcal/mol]      1.066    0.765\n",
      "    forces mae [kcal/mol/Å]    1.610    1.468\n",
      "epoch:  96                    train:   valid:\n",
      "    loss [a.u.]                2.828    2.459\n",
      "    energy mae [kcal/mol]      0.700    0.894\n",
      "    forces mae [kcal/mol/Å]    1.612    1.407\n",
      "epoch:  97                    train:   valid:\n",
      "    loss [a.u.]                2.194    2.114\n",
      "    energy mae [kcal/mol]      0.704    0.546\n",
      "    forces mae [kcal/mol/Å]    1.396    1.451\n",
      "epoch:  98                    train:   valid:\n",
      "    loss [a.u.]                2.582    2.360\n",
      "    energy mae [kcal/mol]      0.940    0.654\n",
      "    forces mae [kcal/mol/Å]    1.446    1.501\n",
      "epoch:  99                    train:   valid:\n",
      "    loss [a.u.]                2.669    3.459\n",
      "    energy mae [kcal/mol]      0.838    0.796\n",
      "    forces mae [kcal/mol/Å]    1.524    1.737\n",
      "epoch:  100                    train:   valid:\n",
      "    loss [a.u.]                3.669    6.081\n",
      "    energy mae [kcal/mol]      1.104    2.239\n",
      "    forces mae [kcal/mol/Å]    1.726    2.029\n"
     ]
    }
   ],
   "source": [
    "# Create PRNGKeys.\n",
    "data_key, train_key = jax.random.split(jax.random.PRNGKey(0), 2)\n",
    "\n",
    "# Draw training and validation sets.\n",
    "train_data, valid_data, _ = prepare_datasets(data_key, num_train=num_train, num_valid=num_valid)\n",
    "\n",
    "# Create and train model.\n",
    "message_passing_model = MessagePassingModel(\n",
    "  features=features,\n",
    "  max_degree=max_degree,\n",
    "  num_iterations=num_iterations,\n",
    "  num_basis_functions=num_basis_functions,\n",
    "  cutoff=cutoff,\n",
    ")\n",
    "params = train_model(\n",
    "  key=train_key,\n",
    "  model=message_passing_model,\n",
    "  train_data=train_data,\n",
    "  valid_data=valid_data,\n",
    "  num_epochs=num_epochs,\n",
    "  learning_rate=learning_rate,\n",
    "  forces_weight=forces_weight,\n",
    "  batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax  # Ensure flax is imported for serialization\n",
    "serialized_params = flax.serialization.to_bytes(params)\n",
    "with open('model_params.bin', 'wb') as f:\n",
    "    f.write(serialized_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
